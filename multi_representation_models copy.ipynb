{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de34339f",
   "metadata": {},
   "source": [
    "Create multiple labels for each topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dacy\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired, PartOfSpeech\n",
    "from copy import deepcopy\n",
    "\n",
    "# Set up the directory paths\n",
    "models_dir = './metrics_by_model'\n",
    "datasets_dir = './complete_datasets'\n",
    "output_dir = './multi_rep_topiclabels'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "nlp = dacy.load(\"da_dacy_medium_trf-0.2.0\")\n",
    "\n",
    "# Iterate over each subdirectory in models_dir\n",
    "for subdir in os.listdir(models_dir):\n",
    "    subdir_path = os.path.join(models_dir, subdir)\n",
    "    \n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(subdir_path):\n",
    "        model_path = os.path.join(subdir_path, f\"{subdir}_topic_model\")\n",
    "        dataset_path = os.path.join(datasets_dir, f\"{subdir}.csv\")\n",
    "\n",
    "        # Check if model and dataset files exist\n",
    "        if not os.path.exists(model_path) or not os.path.exists(dataset_path):\n",
    "            print(f\"Model or dataset file not found for {subdir}\")\n",
    "            continue\n",
    "\n",
    "        # Load model and dataset\n",
    "        topic_model = BERTopic.load(model_path)\n",
    "        text_data = pd.read_csv(dataset_path, index_col=0)\n",
    "        docs = text_data['text']\n",
    "        lem_docs = [\" \".join([token.lemma_ for token in nlp(doc)]) for doc in docs]\n",
    "\n",
    "        # Original c-TF-IDF Representation\n",
    "        original_ctfidf_info = topic_model.get_topic_info()\n",
    "\n",
    "        # Define the different representation models\n",
    "        keybert_model = KeyBERTInspired()\n",
    "        pos_model = PartOfSpeech(model=nlp)\n",
    "        mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "        # Create copies of the original model for each representation\n",
    "        topic_model_keybert = deepcopy(topic_model)\n",
    "        topic_model_keybertlem = deepcopy(topic_model)\n",
    "        topic_model_pos = deepcopy(topic_model)\n",
    "        topic_model_mmr = deepcopy(topic_model)\n",
    "\n",
    "        # Update copies with respective representation models\n",
    "        topic_model_keybert.update_topics(docs, representation_model=keybert_model)\n",
    "        topic_model_keybertlem.update_topics(lem_docs, representation_model=keybert_model)\n",
    "        topic_model_pos.update_topics(lem_docs, representation_model=pos_model)\n",
    "        topic_model_mmr.update_topics(docs, representation_model=mmr_model)\n",
    "\n",
    "        # Extract topic information from each model\n",
    "        keybert_info = topic_model_keybert.get_topic_info()\n",
    "        keybertlem_info = topic_model_keybertlem.get_topic_info()\n",
    "        pos_info = topic_model_pos.get_topic_info()\n",
    "        mmr_info = topic_model_mmr.get_topic_info()\n",
    "\n",
    "        # Combine all representations into a single DataFrame\n",
    "        combined_df = pd.DataFrame({\n",
    "            'Topic': original_ctfidf_info['Topic'],\n",
    "            'Count': original_ctfidf_info['Count'],\n",
    "            'cTFIDF': original_ctfidf_info['Name'],\n",
    "            'KeyBert': keybert_info['Name'],\n",
    "            'KeyBert_lem':keybertlem_info['Name'],\n",
    "            'DaCY_PoS': pos_info['Name'],\n",
    "            'MMR': mmr_info['Name'],\n",
    "        })\n",
    "\n",
    "        combined_df\n",
    "\n",
    "        # Save the combined DataFrame as a CSV file\n",
    "        output_file_path = os.path.join(output_dir, f\"{subdir}_combined_representations.csv\")\n",
    "        combined_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "        print(f\"Saved combined representations for {subdir} to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bertopic]",
   "language": "python",
   "name": "conda-env-bertopic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
