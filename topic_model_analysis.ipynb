{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce264ce",
   "metadata": {},
   "source": [
    "Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87afd7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import hdbscan\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1f608",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(model):\n",
    "    probs = hdbscan.all_points_membership_vectors(model.hdbscan_model)\n",
    "    prob_df = pd.DataFrame(model._map_probabilities(probs, original_topics=True)).transpose()\n",
    "    return prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get documents for each topic from model\n",
    "def extract_docs_per_topic(doc_df, prob_df, n, multi_text=True):\n",
    "    '''\n",
    "    Extract the first n documents corresponding to each topic as fitted by the model \n",
    "    according to the probability scores. \n",
    "    '''\n",
    "    col_names = ['Topic '+str(i) for i in range(prob_df.shape[0])]\n",
    "    docs_per_topic_df = pd.DataFrame(columns=col_names, index=range(n))\n",
    "    if multi_text is True: \n",
    "        books_per_topic_df = pd.DataFrame(columns=col_names, index=range(n))\n",
    "    ind_list = []\n",
    "    for i in range(prob_df.shape[0]):\n",
    "        ind_list = list(prob_df.sort_values(by=i, axis=1, ascending=False).iloc[:, :n].columns)\n",
    "        doc_list = []\n",
    "        if multi_text is True: \n",
    "            book_list = []\n",
    "        for j in ind_list:\n",
    "            doc_list.append(doc_df.iloc[j, 0])\n",
    "            if multi_text is True: \n",
    "                book_list.append(doc_df.iloc[j, 1])\n",
    "        docs_per_topic_df['Topic '+str(i)] = doc_list\n",
    "        if multi_text is True: \n",
    "            books_per_topic_df['Topic '+str(i)] = book_list\n",
    "            joint_df = docs_per_topic_df.join(\n",
    "                books_per_topic_df, lsuffix='_doc', rsuffix='_text_name').sort_index(axis=1)\n",
    "    if multi_text is True: \n",
    "        return docs_per_topic_df, books_per_topic_df, joint_df\n",
    "    return docs_per_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(book_df):\n",
    "    return book_df.apply(pd.Series.value_counts, axis=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique(tale_df, doc_df, n):\n",
    "    '''\n",
    "    Input: \n",
    "        data frame of topics vs. tale names, data frame of topics vs. docs\n",
    "    Output: \n",
    "        a data frame, rows are topics, 6 columns as follows:\n",
    "            For every topic, \n",
    "                tale_unique_prob: list of unique tale/book with highest probability documents\n",
    "                doc_unique_prob: the first document from each tale/book in tale_unique_prob\n",
    "                doc_ind_prob: the indices of the selected documents in doc_unique_prob\n",
    "                tale_unique_freq: list of unique tale/book with the most documents\n",
    "                doc_unique_freq: the first document from each tale/book in tale_unique_freq\n",
    "                doc_ind_freq: the indices of the selected documents in doc_unique_freq\n",
    "    Extract the top n unique tales/books and their corresponding documents for every topic\n",
    "    based on probability and frequency\n",
    "    '''\n",
    "\n",
    "    topic_list = list(tale_df.columns)\n",
    "\n",
    "    tale_unique_prob = []\n",
    "    doc_unique_prob = []\n",
    "    doc_ind_prob = []\n",
    "    tale_unique_freq = []\n",
    "    doc_unique_freq = []\n",
    "    doc_ind_freq = []\n",
    "\n",
    "    for topic in topic_list:\n",
    "        tale_group = tale_df.groupby(topic).groups\n",
    "        for key in tale_group.keys():\n",
    "            tale_group[key] = list(tale_group[key])\n",
    "        n_prob = sorted(tale_group.items(), key=lambda item: item[1])[:n]\n",
    "        ind_prob = [n_prob[i][1][0] for i in range(len(n_prob))]\n",
    "        n_freq = sorted(tale_group.items(), key=lambda item: len(item[1]), reverse=True)[:n]\n",
    "        ind_freq = [n_freq[i][1][0] for i in range(len(n_freq))]\n",
    "        tale_unique_prob.append([n_prob[i][0] for i in range(len(n_prob))])\n",
    "        doc_unique_prob.append(list(doc_df[topic].iloc[ind_prob]))\n",
    "        doc_ind_prob.append(ind_prob)\n",
    "        tale_unique_freq.append([n_freq[i][0] for i in range(len(n_freq))])\n",
    "        doc_unique_freq.append(list(doc_df[topic].iloc[ind_freq]))\n",
    "        doc_ind_freq.append(ind_freq)\n",
    "  \n",
    "    return pd.DataFrame(data={'tale_unique_prob': tale_unique_prob, 'doc_unique_prob': doc_unique_prob, \n",
    "                            'doc_ind_prob': doc_ind_prob, 'tale_unique_freq': tale_unique_freq, \n",
    "                            'doc_unique_freq': doc_unique_freq, 'doc_ind_freq': doc_ind_freq}, \n",
    "                      index=topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_labels(model, nr_words=5, topic_prefix=True, separator=', '):\n",
    "    '''\n",
    "    Customize labels for each topic in model\n",
    "    Input: \n",
    "        model: fitted topic model\n",
    "        nr_words: top n words per topic to use\n",
    "        topic_prefix: whether to use the topic ID as a prefix\n",
    "        separator: the string with which the words and topic prefix will be separated\n",
    "    '''\n",
    "    topic_labels = model.generate_topic_labels(nr_words=nr_words, topic_prefix=topic_prefix, separator=separator)\n",
    "    model.set_topic_labels(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73302c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipartite_graph(df):\n",
    "    B = nx.Graph()\n",
    "    for i in df.index:\n",
    "        B.add_node(i, bipartite=0)\n",
    "        for j in df.columns:\n",
    "            B.add_node(j, bipartite=1)\n",
    "            if (df.loc[i,j] > 0.0):\n",
    "                B.add_edge(i, j, weight=df.loc[i,j])\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f782ae",
   "metadata": {},
   "source": [
    "Load models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danish\n",
    "\n",
    "# travel datasets\n",
    "sweden_danish_df = pd.read_csv('./small/sverrig.csv', index_col=0)\n",
    "poets_danish_df = pd.read_csv('./small/bazar.csv', index_col=0)\n",
    "spain_danish_df = pd.read_csv('./small/spanien.csv', index_col=0)\n",
    "rambles_danish_df = pd.read_csv('./small/skygge.csv', index_col=0)\n",
    "travel_dan_df = pd.read_csv('./large/travels_dan.csv', index_col=0)\n",
    "\n",
    "# fairytale datasets\n",
    "tale_danish_df = pd.read_csv(\"./large/tales_dan.csv\", index_col=0)\n",
    "\n",
    "# combined corpuses\n",
    "travel_fairytales_df = pd.read_csv('./large/travels_tales_dan.csv', index_col=0)\n",
    "group0 = pd.read_csv('./small/group_0.csv')\n",
    "group1_skygge = pd.read_csv('./large/group_1.csv', index_col=0)\n",
    "group2_bazar = pd.read_csv('./large/group_2.csv', index_col=0)\n",
    "group3_sverrig = pd.read_csv('./large/group_3.csv', index_col=0)\n",
    "group4_spanien = pd.read_csv('./large/group_4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecebdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_dan = [sweden_danish_df, poets_danish_df, spain_danish_df, rambles_danish_df, \n",
    "               travel_dan_df, tale_danish_df, travel_fairytales_df, group1_skygge, group2_bazar, \n",
    "               group3_sverrig, group4_spanien]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960098c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list_dan:\n",
    "     print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danish\n",
    "\n",
    "# travelogue models\n",
    "sverrig = BERTopic.load('./sverrig_topic_model')\n",
    "bazar = BERTopic.load('./bazar_topic_model')\n",
    "spanien = BERTopic.load('./spanien_topic_model')\n",
    "skygge = BERTopic.load('./skygge_topic_model')\n",
    "travel_dan = BERTopic.load('./travels_dan_topic_model')\n",
    "\n",
    "# fairytale models\n",
    "tales_danish = BERTopic.load(\"./tales_dan_topic_model\")\n",
    "\n",
    "# combined corpuses\n",
    "full_travels_tales_dan = BERTopic.load(\"./travels_tales_dan_topic_model\")\n",
    "group1_skygge_model = BERTopic.load(\"./group_1_topic_model\")\n",
    "group2_bazar_model = BERTopic.load(\"./group_2_topic_model\")\n",
    "group3_sverrig_model = BERTopic.load(\"./group_3_topic_model\")\n",
    "group4_spanien_model = BERTopic.load(\"./group_4_topic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_dan = [sverrig, bazar, spanien, skygge, travel_dan, tales_danish, full_travels_tales_dan, \n",
    "                  group1_skygge_model, group2_bazar_model, group3_sverrig_model, group4_spanien_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32c5c0",
   "metadata": {},
   "source": [
    "Get documents for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10343fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability matrices for models\n",
    "prob_list = []\n",
    "for model in (model_list_dan):\n",
    "    prob_list.append(get_probs(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_single_text = dict()\n",
    "docs_multi_text = dict()\n",
    "books = dict()\n",
    "joints = dict()\n",
    "freqs = dict()\n",
    "\n",
    "keys = ['sverrig', 'bazar', 'spanien', 'skygge', 'travel_dan', 'tales_danish', 'travels_tales_dan', 'group1_skygge', \n",
    "        'group2_bazar', 'group3_sverrig', 'group4_spanien']\n",
    "\n",
    "N = 50 #this number can be changed depending on application\n",
    "\n",
    "for i in range(len(model_list_dan)):\n",
    "    if (i < 4): \n",
    "        docs_single_text[keys[i]] = extract_docs_per_topic((df_list_dan)[i], \n",
    "                                                           prob_list[i], n=N, multi_text=False)\n",
    "    else: \n",
    "        doc, book, joint = extract_docs_per_topic((df_list_dan)[i], prob_list[i], n=N)\n",
    "        docs_multi_text[keys[i]] = doc\n",
    "        books[keys[i]] = book\n",
    "        joints[keys[i]] = joint\n",
    "        freqs[keys[i]] = get_frequency(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29cfeae",
   "metadata": {},
   "source": [
    "Tabular summary of travelogue models (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51304b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(model.get_topics()) for model in model_list_dan[:-1]])\n",
    "travel_summary = pd.DataFrame(index=range(max_len))\n",
    "col_dict = dict()\n",
    "keys = ['sverrig', 'bazar', 'spanien', 'skygge', 'travel_dan']\n",
    "for i in range(len(keys)):\n",
    "    custom_labels(model_list_dan[i])\n",
    "    col_dict[keys[i]] = model_list_dan[i].custom_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e04c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col_data in col_dict.items():\n",
    "    if len(col_data) < max_len:\n",
    "        col_data += [float('nan')] * (max_len - len(col_data))\n",
    "    travel_summary[col_name] = col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3textsdan = books['travel_dan'].iloc[:3, :].T.rename(columns={0:'Text_1', 1:'Text_2', 2:'Text_3'})\n",
    "books['travel_dan'].columns\n",
    "top3docsdan = docs_multi_text['travel_dan'].iloc[:3, :].T.rename(columns={0:'Doc_1', 1:'Doc_2', 2:'Doc_3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee15d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traveldan_topics_df = pd.DataFrame(model_list_dan[4].get_topics())\n",
    "traveldan_topics_df.rename(columns=dict(zip(range(traveldan_topics_df.shape[1]-1), ['Topic '+str(i) for i in range(101)])), \n",
    "                  inplace=True)\n",
    "traveldan_topics_df = traveldan_topics_df.applymap(lambda x:x[0])\n",
    "traveldan_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ecc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3wordsdan = traveldan_topics_df.iloc[:3, 1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b47b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc_traveldan_df = pd.concat([top3wordsdan, top3docsdan, top3textsdan], axis=1)\n",
    "topic_doc_traveldan_df['top3wordsdan'] = topic_doc_traveldan_df[[0, 1, 2]].astype(str).agg(', '.join, axis=1)\n",
    "topic_doc_traveldan_df.drop([0,1,2], axis=1, inplace=True)\n",
    "# uncomment following for inspection\n",
    "#topic_doc_traveldan_df\n",
    "#topic_doc_traveldan_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd62e6",
   "metadata": {},
   "source": [
    "More analysis on full combined corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3texts = books['travels_tales_dan'].iloc[:3, :].T.rename(columns={0:'Text_1', 1:'Text_2', 2:'Text_3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3docs = docs_multi_text['travels_tales_dan'].iloc[:3, :].T.rename(columns={0:'Doc_1', 1:'Doc_2', 2:'Doc_3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = pd.DataFrame(model_list_dan[6].get_topics())\n",
    "all_topics_df.rename(columns=dict(zip(range(all_topics_df.shape[1]-1), ['Topic '+str(i) for i in range(101)])), \n",
    "                  inplace=True)\n",
    "all_topics_df = all_topics_df.applymap(lambda x:x[0])\n",
    "all_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce893313",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3words = all_topics_df.iloc[:3, 1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c450a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3words.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bffd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_doc_tale_df = pd.concat([top3words, top3docs, top3texts], axis=1)\n",
    "topic_doc_tale_df['top3words'] = topic_doc_tale_df[[0, 1, 2]].applymap(str).agg(', '.join, axis=1)\n",
    "topic_doc_tale_df.drop([0,1,2], axis=1, inplace=True)\n",
    "topic_doc_tale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_unique(books['travels_tales_dan'], docs_multi_text['travels_tales_dan'], 3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = list(books['travels_tales_dan'].columns)\n",
    "df2 = pd.DataFrame(df['tale_unique_prob'].to_list(), columns=['tale_prob_1','tale_prob_2', 'tale_prob_3'], index=topic_list)\n",
    "df3 = pd.DataFrame(df['doc_unique_prob'].to_list(), columns=['doc_prob_1','doc_prob_2', 'doc_prob_3'], index=topic_list)\n",
    "df4 = pd.DataFrame(df['tale_unique_freq'].to_list(), columns=['tale_freq_1','tale_freq_2', 'tale_freq_3'], index=topic_list)\n",
    "df5 = pd.DataFrame(df['doc_unique_freq'].to_list(), columns=['doc_freq_1','doc_freq_2', 'doc_freq_3'], index=topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f786ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_prob = pd.DataFrame(df['doc_ind_prob'])\n",
    "ind_freq = pd.DataFrame(df['doc_ind_freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = pd.DataFrame(topic_doc_tale_df['top3words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 texts and top 3 documents for each topic by probability\n",
    "topic_doc_tale_prob = pd.concat([topic_words, df2, df3, ind_prob], axis=1)\n",
    "topic_doc_tale_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 texts and top 3 documents for each topic by document frequency\n",
    "topic_doc_tale_freq = pd.concat([topic_words, df4, df5, ind_freq], axis=1)\n",
    "topic_doc_tale_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019e36f",
   "metadata": {},
   "source": [
    "# Visualizations for multi-text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280c018",
   "metadata": {},
   "source": [
    "Stacked bar chart for full travelogue model (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ab8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig2 = px.bar(freqs['travel_dan'].T)\n",
    "fig2.update_layout(xaxis_title_text='Topics', yaxis_title_text='Counts', legend_title='Book')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49247d1",
   "metadata": {},
   "source": [
    "Heatmaps for fairytale corpus and combined corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairytale corpus \n",
    "fig4 = px.imshow(freqs['tales_danish'], color_continuous_scale='ice_r', range_color=[0,20], width=750, height=750)\n",
    "fig4.update_layout(xaxis_title_text='Topics', yaxis_title_text='Fairytales', \n",
    "                   title_text='Heatmap for Fairytale Model')\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined corpuses \n",
    "fig6 = px.imshow(freqs['travels_tales_dan'], color_continuous_scale='ice_r', \n",
    "                 range_color=[0,30], width=1000, height=1000)\n",
    "fig6.update_layout(xaxis_title_text='Topics', yaxis_title_text='Fairytales and Travelogues', \n",
    "                   title_text='Heatmap for Combined Corpuses Model (Danish)')\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig100 = px.bar(freqs['travels_tales_dan'].loc[['bazar', 'skygge', 'spanien', 'sverrig']].T)\n",
    "fig100.update_layout(xaxis_title_text='Topics', yaxis_title_text='Counts', legend_title='Book')\n",
    "fig100.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dca70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig101 = px.bar(freqs['travels_tales_dan']['Topic 54'])\n",
    "fig101.update_layout(xaxis_title_text='Title', yaxis_title_text='Counts', legend_title='Topic')\n",
    "fig101.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic ID for the bar chart\n",
    "topic_id = 'Topic 5'\n",
    "\n",
    "# Get the top 3 words for 'Topic 54' from the 'topic_doc_tale_df' DataFrame\n",
    "top3_words_for_topic = topic_doc_tale_df.loc[topic_id, 'top3words']\n",
    "\n",
    "# Create the bar chart\n",
    "fig101 = px.bar(freqs['travels_tales_dan']['Topic 5'])\n",
    "\n",
    "# Combine the topic number and top 3 words for the legend title\n",
    "legend_title = f\"{topic_id}: {''.join(top3_words_for_topic)}\"\n",
    "\n",
    "# Update the layout of the bar chart\n",
    "fig101.update_layout(\n",
    "    xaxis_title_text='Title',\n",
    "    yaxis_title_text='Counts',\n",
    "    legend_title=legend_title  # Update the legend title\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig101.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqs: DataFrame containing frequencies of documents associated with each topic\n",
    "freqs['travels_tales_dan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7901d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_doc_tale_df: DataFrame containing the top 3 words for each topic\n",
    "# List of topic IDs to plot\n",
    "topic_ids_to_plot = ['Topic 5', 'Topic 10', 'Topic 15']\n",
    "\n",
    "# Create empty list to store the dataframes for each topic\n",
    "dataframes_for_each_topic = []\n",
    "\n",
    "# Loop through each topic ID and create dataframe for that topic\n",
    "for topic_id in topic_ids_to_plot:\n",
    "    # Get top 3 words for the current topic\n",
    "    top3_words_for_topic = topic_doc_tale_df.loc[topic_id, 'top3words']\n",
    "    \n",
    "    # Create new dataframe with the data for the current topic\n",
    "    df_topic = freqs['travels_tales_dan'].copy()\n",
    "    df_topic['Title'] = df_topic.index  # Use the index as the title value for each topic\n",
    "    df_topic['Counts'] = df_topic[topic_id]\n",
    "    df_topic['Topic'] = f\"{topic_id}: {''.join(top3_words_for_topic)}\"\n",
    "    \n",
    "    # Append dataframe to the list\n",
    "    dataframes_for_each_topic.append(df_topic)\n",
    "\n",
    "# Concatenate dataframes for all topics into a single dataframe\n",
    "combined_df = pd.concat(dataframes_for_each_topic)\n",
    "\n",
    "# Create a single bar chart with different colored bars for each topic\n",
    "fig104 = px.bar(combined_df, x='Title', y='Counts', color='Topic',\n",
    "                labels={'Title': 'Title', 'Counts': 'Counts'},\n",
    "                category_orders={'Topic': topic_ids_to_plot})\n",
    "\n",
    "# Update the layout of the bar chart\n",
    "fig104.update_layout(\n",
    "    xaxis_title_text='Title',\n",
    "    yaxis_title_text='Counts',\n",
    "    barmode='group'  # Set the barmode to 'group' for different colored bars\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig104.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0bfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairytale group1 + Skygge (Danish)\n",
    "fig7 = px.imshow(freqs['group1_skygge'], color_continuous_scale='ice_r', \n",
    "                 range_color=[0,30], width=750, height=750)\n",
    "fig7.update_layout(xaxis_title_text='Topics', yaxis_title_text='Text titles', \n",
    "                   title_text='Heatmap for Skyggebilleder and Same Period Fairytales Model (Danish)')\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairytale group2 + Bazar (Danish)\n",
    "fig9 = px.imshow(freqs['group2_bazar'], color_continuous_scale='ice_r', \n",
    "                 range_color=[0,30], width=750, height=750)\n",
    "fig9.update_layout(xaxis_title_text='Topics', yaxis_title_text='Text titles', \n",
    "                   title_text='Heatmap for En Digters Bazar and Same Period Fairytales Model (Danish)')\n",
    "fig9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairytale group3 + Sverrig (Danish)\n",
    "fig11 = px.imshow(freqs['group3_sverrig'], color_continuous_scale='ice_r', \n",
    "                 range_color=[0,30], width=750, height=750)\n",
    "fig11.update_layout(xaxis_title_text='Topics', yaxis_title_text='Text titles', \n",
    "                   title_text='Heatmap for I Sverrig and Same Period Fairytales Model (Danish)')\n",
    "fig11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c75e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairytale group4 + Spanien (Danish)\n",
    "fig13 = px.imshow(freqs['group4_spanien'], color_continuous_scale='ice_r', \n",
    "                 range_color=[0,30], width=750, height=750)\n",
    "fig13.update_layout(xaxis_title_text='Topics', yaxis_title_text='Text titles', \n",
    "                   title_text='Heatmap for I Spanien and Et Besoeg i Portugal and Same Period Fairytales Model (Danish)')\n",
    "fig13.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae138629",
   "metadata": {},
   "source": [
    "Line graph of document contributions per topic in combined corpuses model -- see figure 2 in article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig14 = go.Figure()\n",
    "for i in range(prob_list[6].shape[0]): \n",
    "    fig14.add_trace(go.Scatter(x=np.arange(prob_list[6].shape[1]), \n",
    "                              y=prob_list[6].iloc[i].sort_values(ascending=False),\n",
    "                              mode='lines', name=\"Topic \"+str(i)))\n",
    "# fig.add_trace(go.Scatter(x=np.arange(full_prob_df.shape[1]), y=[0.2]*100, mode='lines'))\n",
    "fig14.update_layout(legend_title=\"Topics\", xaxis_title_text=\"Documents\", \n",
    "                   yaxis_title_text=\"Probability\", \n",
    "                   title_text=\"First 100 Document Contributions per Topic in Combined Corpuses Model\")\n",
    "fig14.update_xaxes(range=[0,100])\n",
    "fig14.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3d71a",
   "metadata": {},
   "source": [
    "## Bipartite Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede7db2",
   "metadata": {},
   "source": [
    "All fairytales model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_fairytale_dan = bipartite_graph(freqs['tales_danish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c249ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "nx.draw_networkx(B_fairytale_dan, pos=nx.drawing.layout.bipartite_layout(B_fairytale_dan, \n",
    "                                                                         list(freqs['tales_danish'].index)), \n",
    "                 with_labels=False, node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ddb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(B_fairytale_dan, \"./reduced_bigraphs/fairytales_danish_bigraph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db8bda",
   "metadata": {},
   "source": [
    "### Full model (travel + tales) (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_all_dan = bipartite_graph(freqs['travels_tales_dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "nx.draw_networkx(B_all_dan, pos=nx.drawing.layout.bipartite_layout(B_all_dan, list(freqs['travels_tales_dan'].index)), \n",
    "                 with_labels=False, node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41907d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(B_all_dan, \"./reduced_bigraphs/danish_travel_fairytale_bigraph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1b80e",
   "metadata": {},
   "source": [
    "### Group 1: Skygge + fairytales (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e402a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_skygge = bipartite_graph(freqs['group1_skygge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120efad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw_networkx(B_skygge, pos=nx.drawing.layout.bipartite_layout(B_skygge, list(freqs['group1_skygge'].index)), \n",
    "                 with_labels=False, node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(B_skygge, \"./reduced_bigraphs/group1_skygge_bigraph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a8f4f",
   "metadata": {},
   "source": [
    "### Group 2: Bazar + fairytales (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72902c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_bazar = bipartite_graph(freqs['group2_bazar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456373a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw_networkx(B_bazar, pos=nx.drawing.layout.bipartite_layout(B_bazar, list(freqs['group2_bazar'].index)), \n",
    "                 with_labels=False, node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86264d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(B_bazar, \"./reduced_bigraphs/group2_bazar_bigraph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab69a3",
   "metadata": {},
   "source": [
    "### Group 3: Sverrig + fairytales (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_sverrig = bipartite_graph(freqs['group3_sverrig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw_networkx(B_sverrig, pos=nx.drawing.layout.bipartite_layout(B_sverrig, list(freqs['group3_sverrig'].index)), \n",
    "                 with_labels=False, node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b39e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(B_sverrig, \"./reduced_bigraphs/group3_sverrig_bigraph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a936b",
   "metadata": {},
   "source": [
    "### Group 4: Spanien + fairytales (Danish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_spanien = bipartite_graph(freqs['group4_spanien'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6683a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw_networkx(B_spanien, pos=nx.drawing.layout.bipartite_layout(B_spanien, list(freqs['group4_spanien'].index)), \n",
    "                 with_labels=False, node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(B_spanien, \"./reduced_bigraphs/group4_spanien_bigraph.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bertopic]",
   "language": "python",
   "name": "conda-env-bertopic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
